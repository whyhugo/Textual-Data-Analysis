{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from lxml import etree\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links():\n",
    "    links = []\n",
    "\n",
    "    h2_tags = sp.find_all('h2')\n",
    "    for h2_tag in h2_tags:\n",
    "        a_tag = h2_tag.find('a')\n",
    "        if a_tag and 'href' in a_tag.attrs:\n",
    "            links.append(a_tag['href'])\n",
    "    return links\n",
    "\n",
    "def get_article_title():\n",
    "    try:\n",
    "        title = sp.find('h1', class_='article-title').text\n",
    "        return title if title else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_article_date():\n",
    "    try:\n",
    "        date = sp.find('time').text[:10]\n",
    "        return date\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_article_summary():\n",
    "    try:\n",
    "        div_tag = sp.find_all('div', class_=\"articleimg\")\n",
    "        for text in div_tag:\n",
    "            summary = text.get_text()\n",
    "        return summary \n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_article_text():\n",
    "    try:\n",
    "        text = ''\n",
    "\n",
    "        div_tags = sp.find_all('div', class_=\"post-article text-align-left\")\n",
    "        for div_tag in div_tags:\n",
    "            p_tags = div_tag.find_all('p')\n",
    "            for p_tag in p_tags:\n",
    "                text += p_tag.get_text()    \n",
    "        return text\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['報導標題', '報導日期', '報導大意', '報導內文']\n",
    "df = pd.DataFrame([[0, 0, 0, 0]], columns=column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_type = 'supplement'\n",
    "\n",
    "for page_num in range(1, 2):\n",
    "    print(f'Page {page_num} start')\n",
    "    url = 'https://news.pts.org.tw/' + report_type + '?page=' + str(page_num)\n",
    "    html = rq.get(url)\n",
    "    sp = soup(html.text, 'lxml')\n",
    "    links_in_this_page = get_links()\n",
    "    for link in links_in_this_page:\n",
    "        html = rq.get(link)\n",
    "        sp = soup(html.text, 'lxml')\n",
    "        title = get_article_title()\n",
    "        date = get_article_date()\n",
    "        summary = get_article_summary()\n",
    "        text = get_article_text()\n",
    "        df = df.append(pd.DataFrame([[title, date, summary, text]], columns=column_name), ignore_index=True)\n",
    "    print(f'Page {page_num} end')\n",
    "    \n",
    "df = df.drop(0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/pts_{report_type}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
